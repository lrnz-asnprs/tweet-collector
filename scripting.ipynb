{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex for special characters\n",
    "from random import random\n",
    "from tweet_collector.modules.tweet_collector import *\n",
    "import os, re, pandas as pd\n",
    "from datetime import datetime\n",
    "from definitions import ROOT_DIR\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The United States has \"10,000 IRS agents making sure that you don\\'t take an improper charity deduction,\" but to fight terrorism, it has \"less than two dozen people focusing on countering violent extremism at home.\"'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "politifact = pd.read_csv(ROOT_DIR+\"/data/fakenews_sources/politifact_scape_2609.csv\")\n",
    "\n",
    "dont_sample = politifact[politifact.claim.str.contains('don\\'t')]\n",
    "\n",
    "sample = dont_sample.sample(10, random_state=42).reset_index()\n",
    "\n",
    "test = 0\n",
    "\n",
    "sample.claim[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_excluded_words(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    tweet_tokenizer = TweetTokenizer()\n",
    "    word_tokens = tweet_tokenizer.tokenize(text)\n",
    "    #stopword removal\n",
    "    word_tokens = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "    #special characters\n",
    "    word_tokens = [w for w in word_tokens if not re.match(r\"[^A-Za-z0-9]\", w)]\n",
    "    filtered_sentence = []\n",
    "    \n",
    "    return \" \".join(word_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'United States 10,000 IRS agents making sure take improper charity deduction fight terrorism less two dozen people focusing countering violent extremism home'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "remove_excluded_words(sample.claim[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_character_limit(character_limit, text):\n",
    "    tweet_tokenizer = TweetTokenizer()\n",
    "    word_tokens = tweet_tokenizer.tokenize(text) \n",
    "    \n",
    "    sentence = [\" \".join([w]) for w in word_tokens if len(sentence)<character_limit]\n",
    "    \n",
    "    return sentence\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_claims(sample):\n",
    "    # #Cleaning step 1 - getting rid of \\n appearances and weird spaces\n",
    "    # sample['claim'] = sample.claim.apply(lambda x: x.strip())\n",
    "\n",
    "    # #Cleaning from all special characters - note the \\w'\\w is to avoid removing the ' in don't, won't they've etc.\n",
    "    # sample['claim'] = sample.claim.apply(lambda x: re.sub(r'[^a-zA-Z0-9 \\w\\'\\w \\.,]', '', x))\n",
    "\n",
    "    # Removing \"Says\" in the beginning of a statement around 1000 claim quotes in the sample have this sentence structure.\n",
    "    # Fine to remove as the quote after is the essence of the claim.\n",
    "    sample['claim'] = sample.claim.apply(lambda x: re.sub(r'^Says', '', x).strip())\n",
    "    \n",
    "    # remove stopwords - done in order to avoid query errors such as:\n",
    "    # \"There were errors processing your request: Ambiguous use of and as a keyword. Use a space to logically join two clauses, or \\\"and\\\" to find occurrences of and in text\n",
    "    sample['claim'] = sample.claim.apply(lambda x: remove_excluded_words(x))\n",
    "    \n",
    "\n",
    "def reshape_date_format(sample):\n",
    "    sample['date'] = sample.date.apply(lambda x: str(datetime.strptime(x, '%B %d, %Y').isoformat()+\"Z\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "#Cleaning and preparation\n",
    "clean_claims(sample)\n",
    "reshape_date_format(sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'United States 10,000 IRS agents making sure take improper charity deduction fight terrorism less two dozen people focusing countering violent extremism home'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample.claim[test][0:140]\n",
    "\n",
    "sample.claim[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = 'November 25, 2018'\n",
    "datet = str(datetime.strptime(date, '%B %d, %Y').isoformat()+\"Z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-11-25T00:00:00Z'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datetime.date'>\n"
     ]
    }
   ],
   "source": [
    "date_str = '09-19-2018'\n",
    "\n",
    "date_object = datetime.strptime(date_str, '%m-%d-%Y')[0:-4].date()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-09-29T11:19:05.86Z'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(datetime.today().isoformat()[0:-4]+\"Z\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36e2581dfb10b7e3de3547be529c2e8e9e4d59798f578734b808d68ebdb931d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
